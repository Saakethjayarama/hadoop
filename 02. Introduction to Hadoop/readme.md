# Apache Hadoop : Framework to process big data

- Hadoop is a framework that allows us to store and process large data sets in parallel and distrubuted fashion.
- Two problems
  1. Storage (food shelves) => HDFS (Hadoop cluster)
  2. Processing (cooks and main cook) => MapReduce

## Hadoop Master/Slave Architecture

- Project Manager and Employees
- Project manager -> gets projects assigns to employees and tracks the progress
- Master Node -> Project Manager
- Slave Node -> Employees
- If one of the slave (Employees) fail the others can be used as backup to complete the processes without any hitch.
